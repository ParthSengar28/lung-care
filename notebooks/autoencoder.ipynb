{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f752b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9df648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA DIRECTORIES\n",
    "# =========================\n",
    "train_dir = '../data/train'\n",
    "test_dir = '../data/test'\n",
    "val_dir = '../data/val'\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5f092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# DATA AUGMENTATION\n",
    "# =========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348bf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Class Weights: {0: np.float64(1.9448173005219984), 1: np.float64(0.6730322580645162)}\n"
     ]
    }
   ],
   "source": [
    "# CLASS WEIGHTS\n",
    "# =========================\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Computed Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b779d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Autoencoder...\n",
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     50\u001b[39m encoder = Model(input_img, encoded)\n\u001b[32m     52\u001b[39m autoencoder.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mae_train_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mae_val_generator\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m autoencoder.save(autoencoder_path)\n\u001b[32m     61\u001b[39m encoder.save(encoder_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\lung-care\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\lung-care\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: None values not supported."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# AUTOENCODER\n",
    "# =========================\n",
    "autoencoder_path = \"autoencoder_model.h5\"\n",
    "encoder_path = \"encoder_model.h5\"\n",
    "\n",
    "if os.path.exists(autoencoder_path) and os.path.exists(encoder_path):\n",
    "    print(\"\\nLoading pre-trained Autoencoder and Encoder...\")\n",
    "    autoencoder = load_model(autoencoder_path)\n",
    "    encoder = load_model(encoder_path)\n",
    "else:\n",
    "    print(\"\\nTraining Autoencoder...\")\n",
    "\n",
    "    # ⚡ Separate ImageDataGenerator with no labels\n",
    "    ae_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    ae_train_generator = ae_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,   # no labels\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    ae_val_generator = ae_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,   # no labels\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Define Autoencoder\n",
    "    input_img = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    autoencoder.fit(\n",
    "        ae_train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=ae_val_generator\n",
    "    )\n",
    "\n",
    "    autoencoder.save(autoencoder_path)\n",
    "    encoder.save(encoder_path)\n",
    "    print(\"Autoencoder & Encoder Saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ccbe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "\n",
      "Training Autoencoder...\n",
      "Epoch 1/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 2s/step - loss: 0.0074 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 3/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1s/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 4/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 5/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - loss: 0.0010 - val_loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17d6afe20d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUTOENCODER TRAINING\n",
    "# =========================\n",
    "ae_train_gen_raw = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=None, shuffle=True\n",
    ")\n",
    "ae_val_gen_raw = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=None, shuffle=True\n",
    ")\n",
    "\n",
    "def autoencoder_generator(gen):\n",
    "    for batch in gen:\n",
    "        yield (batch, batch)\n",
    "\n",
    "print(\"\\nTraining Autoencoder...\")\n",
    "autoencoder.fit(\n",
    "    autoencoder_generator(ae_train_gen_raw),\n",
    "    steps_per_epoch=len(ae_train_gen_raw),\n",
    "    epochs=5,\n",
    "    validation_data=autoencoder_generator(ae_val_gen_raw),\n",
    "    validation_steps=len(ae_val_gen_raw)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1cdc595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructing datasets...\n",
      "Train: (5216, 224, 224, 3) Val: (16, 224, 224, 3) Test: (624, 224, 224, 3)\n",
      "\n",
      "Reconstructing datasets...\n",
      "Train: (5216, 224, 224, 3) Val: (16, 224, 224, 3) Test: (624, 224, 224, 3)\n",
      "\n",
      "Reconstructing datasets...\n",
      "Train: (5216, 224, 224, 3) Val: (16, 224, 224, 3) Test: (624, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# RECONSTRUCT DATASETS# RECONSTRUCT DATASETS\n",
    "# =========================\n",
    "def build_reconstructed_dataset(labeled_gen, model_ae):\n",
    "    x_list, y_list = [], []\n",
    "    labeled_gen.reset()\n",
    "    for _ in range(len(labeled_gen)):\n",
    "        x_batch, y_batch = next(labeled_gen)\n",
    "        x_recon = model_ae.predict(x_batch, verbose=0)\n",
    "        x_list.append(x_recon)\n",
    "        y_list.append(y_batch)\n",
    "    return np.concatenate(x_list), np.concatenate(y_list)\n",
    "\n",
    "print(\"\\nReconstructing datasets...\")\n",
    "X_train_recon, y_train = build_reconstructed_dataset(train_generator, autoencoder)\n",
    "X_val_recon, y_val     = build_reconstructed_dataset(validation_generator, autoencoder)\n",
    "X_test_recon, y_test   = build_reconstructed_dataset(test_generator, autoencoder)\n",
    "\n",
    "print(\"Train:\", X_train_recon.shape, \"Val:\", X_val_recon.shape, \"Test:\", X_test_recon.shape)# RECONSTRUCT DATASETS\n",
    "# =========================\n",
    "def build_reconstructed_dataset(labeled_gen, model_ae):\n",
    "    x_list, y_list = [], []\n",
    "    labeled_gen.reset()\n",
    "    for _ in range(len(labeled_gen)):\n",
    "        x_batch, y_batch = next(labeled_gen)\n",
    "        x_recon = model_ae.predict(x_batch, verbose=0)\n",
    "        x_list.append(x_recon)\n",
    "        y_list.append(y_batch)\n",
    "    return np.concatenate(x_list), np.concatenate(y_list)\n",
    "\n",
    "print(\"\\nReconstructing datasets...\")\n",
    "X_train_recon, y_train = build_reconstructed_dataset(train_generator, autoencoder)\n",
    "X_val_recon, y_val     = build_reconstructed_dataset(validation_generator, autoencoder)\n",
    "X_test_recon, y_test   = build_reconstructed_dataset(test_generator, autoencoder)\n",
    "\n",
    "print(\"Train:\", X_train_recon.shape, \"Val:\", X_val_recon.shape, \"Test:\", X_test_recon.shape)\n",
    "# =========================\n",
    "def build_reconstructed_dataset(labeled_gen, model_ae):\n",
    "    x_list, y_list = [], []\n",
    "    labeled_gen.reset()\n",
    "    for _ in range(len(labeled_gen)):\n",
    "        x_batch, y_batch = next(labeled_gen)\n",
    "        x_recon = model_ae.predict(x_batch, verbose=0)\n",
    "        x_list.append(x_recon)\n",
    "        y_list.append(y_batch)\n",
    "    return np.concatenate(x_list), np.concatenate(y_list)\n",
    "\n",
    "print(\"\\nReconstructing datasets...\")\n",
    "X_train_recon, y_train = build_reconstructed_dataset(train_generator, autoencoder)\n",
    "X_val_recon, y_val     = build_reconstructed_dataset(validation_generator, autoencoder)\n",
    "X_test_recon, y_test   = build_reconstructed_dataset(test_generator, autoencoder)\n",
    "\n",
    "print(\"Train:\", X_train_recon.shape, \"Val:\", X_val_recon.shape, \"Test:\", X_test_recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91d8fe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. CLASSIFIER ON TOP OF ENCODER\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# =====================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mencoder\u001b[49m.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m   \u001b[38;5;66;03m# freeze encoder\u001b[39;00m\n\u001b[32m      5\u001b[39m x = encoder.output\n\u001b[32m      6\u001b[39m x = Dense(\u001b[32m256\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m)(x)\n",
      "\u001b[31mNameError\u001b[39m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. CLASSIFIER ON TOP OF ENCODER\n",
    "# =====================\n",
    "encoder.trainable = False   # freeze encoder\n",
    "\n",
    "x = encoder.output\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "classifier_output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier = Model(encoder.input, classifier_output, name=\"classifier\")\n",
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * 0.9\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTraining classifier...\")\n",
    "history = classifier.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[lr_scheduler, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881571b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m early_stop = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining classifier...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m history = \u001b[43mclassifier\u001b[49m.fit(\n\u001b[32m      8\u001b[39m     X_train_recon, y_train,\n\u001b[32m      9\u001b[39m     batch_size=BATCH_SIZE,\n\u001b[32m     10\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m     11\u001b[39m     validation_data=(X_val_recon, y_val),\n\u001b[32m     12\u001b[39m     class_weight=class_weights,\n\u001b[32m     13\u001b[39m     callbacks=[lr_scheduler, early_stop]\n\u001b[32m     14\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# TRAIN CLASSIFIER\n",
    "# =========================\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"\\nTraining classifier...\")\n",
    "history = classifier.fit(\n",
    "    X_train_recon, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val_recon, y_val),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae713f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
